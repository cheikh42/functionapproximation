{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function approximation using RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "import torch.quantization\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from training import *\n",
    "from recurrent import *\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 3 Approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM, Many-to-one approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loading the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_train_3, f3_train, Input_test_3, f3_test, Input_data_3, f3_data =data_splitter(3) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=10**(-2)\n",
    "epochs = 5000\n",
    "alpha=10**(-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(34)\n",
    "loss_array_f3,model_f3= recurrent_model_training_3(epochs, 3, lr, RNN_f3(), alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=[9,6])\n",
    "plt.plot(range(len(loss_array_f3)), loss_array_f3)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.title('loss vs epochs')\n",
    "plt.grid()\n",
    "plt.savefig('./figures/loss_vs_epochs_f3')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log-scale visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=[9,6])\n",
    "plt.plot(range(len(loss_array_f3)), loss_array_f3)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.yscale('log')\n",
    "plt.title('loss vs epochs')\n",
    "plt.grid()\n",
    "plt.savefig('./figures/loss_vs_epochs_f3')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_3=min(loss_array_f3)\n",
    "print(MSE_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing the training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    Input_tr=Input_train_3.reshape(-1, 25, 1)\n",
    "   \n",
    "\n",
    "    f3_approx_train=model_f3.forward(Input_tr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_train=Input_train_3.reshape(len(Input_train_3),-1).numpy()\n",
    "f3_approx_train=np.array(f3_approx_train.reshape(len(Input_train_3),-1))\n",
    "plt.figure(figsize=[9,6])\n",
    "plt.plot(Input_train, f3_approx_train)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f3(x)')\n",
    "plt.title('f3 approximation during training')\n",
    "plt.grid()\n",
    "plt.savefig('./figures/f3_approximation_train')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generalization capacity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    Input_test=Input_test_3.reshape(-1, 25, 1)\n",
    "   \n",
    "\n",
    "    f3_approx_test=model_f3.forward(Input_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_test_3=Input_test_3.flatten()\n",
    "f3_approx_test=np.array(f3_approx_test).flatten()\n",
    "f3_test=np.array(f3_test).flatten()\n",
    "plt.figure(figsize=[9,6])\n",
    "plt.plot(Input_test_3, f3_approx_test, label='Approximation')\n",
    "plt.plot(Input_test_3, f3_test, label='True function ')\n",
    "plt.legend()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f3(x)')\n",
    "plt.title('f3 approximation for testing')\n",
    "plt.grid()\n",
    "plt.savefig('./figures/f3_approximation_test')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    Input_data=Input_data_3.reshape(-1, 25, 1)\n",
    "   \n",
    "\n",
    "    f3_approx=model_f3.forward(Input_data)\n",
    "f3_approx.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_data_array=Input_data.flatten()\n",
    "f3_approx=np.array(f3_approx).flatten()\n",
    "plt.figure(figsize=[9,6])\n",
    "plt.plot(Input_data_array, f3_approx)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f3(x)')\n",
    "plt.title('f3 approximation during training')\n",
    "plt.grid()\n",
    "plt.savefig('./figures/f3_approximation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoom on the testing part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_data_array=Input_data.flatten()\n",
    "f3_approx=np.array(f3_approx).flatten()\n",
    "plt.figure(figsize=[9,6])\n",
    "plt.plot(Input_data_array, f3_approx)\n",
    "plt.xlim(400, 500)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f3(x)')\n",
    "plt.title('f3 approximation during training')\n",
    "plt.axvline(425, color = 'r', linestyle = '-')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "perfectly smooth ?!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quantizing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.quantized.engine = 'qnnpack'\n",
    "NN3_to_be_quantized=model_f3\n",
    "model_int8_f3 = torch.quantization.quantize_dynamic(\n",
    "    model_f3,  # the original model\n",
    "    {torch.nn.Linear},  # a set of layers to dynamically quantize\n",
    "    dtype=torch.qint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effect of quantization on the MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TE_f3=mean_squared_error(np.array(f3_approx_test), np.array(f3_test))\n",
    "print('Non Quantized model performance : ', TE_f3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    Input_test_quant=Input_test_3.reshape(-1, 25, 1)\n",
    "\n",
    "    f3_approx_test_quant=model_int8_f3.forward(Input_test_quant)\n",
    "f3_approx_test_quant.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of the quantized model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TE_f3_Quant=mean_squared_error(np.array(f3_approx_test_quant.flatten()), np.array(f3_test))\n",
    "print('Quantized model performance : ', TE_f3_Quant)\n",
    "print('Non Quantized model performance : ',TE_f3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Performance reduction : {np.ceil(100*(TE_f3_Quant-TE_f3)/TE_f3)} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31300719af4accc410dec3717290851d77bcb807d8c5dcb5063c05c074e53f7d"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
